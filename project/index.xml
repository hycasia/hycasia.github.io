<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | SIR-Smart Iris Recognition</title>
    <link>https://hycasia.github.io/project/</link>
      <atom:link href="https://hycasia.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 02 Sep 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://hycasia.github.io/images/icon_hu42e11727b1bd363727a38d52796c9ff5_15822_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>https://hycasia.github.io/project/</link>
    </image>
    
    <item>
      <title>Iris Recognition</title>
      <link>https://hycasia.github.io/project/iris-recognition/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://hycasia.github.io/project/iris-recognition/</guid>
      <description>&lt;div style=&#34;WIDTH:100%; HEIGHT:100%&#34;&gt;
&lt;font color=#00BFFF size = 5 &gt;&lt;strong&gt; &amp;emsp;&amp;emsp;虹膜识别是进一步提升安全性、可靠性的必由之路&lt;/strong&gt; &amp;emsp;&amp;emsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/font&gt;
&lt;font color=#00BFFF size = 5 &gt;&lt;strong&gt; &amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;———谭铁牛院士&lt;/strong&gt;&lt;/font&gt;  
&lt;div style=&#34;width:800px;&#34;&gt;&lt;font color=#000000 size = 5 &gt;&amp;emsp;&amp;emsp;虹膜识别是最具潜力的生物识别方法之一，是识别率高、非接触性、防欺骗性好的识别方法。虹膜属于人眼的一部分，如下图所示。&lt;/font&gt;
&lt;div style=&#34;float:right; clear: both;&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;iris.png&#34; width=&#34;300&#34; alt=&#34;&#34; hspace=&#34;8&#34;&gt;&lt;br /&gt;&lt;/div&gt;
&lt;div style=&#34;width:800px;&#34;&gt;&lt;font color=#000000 size = 5 &gt;&amp;emsp;&amp;emsp;人眼的外观主要由巩膜、虹膜、瞳孔三部分组成，其中巩膜即眼球外围的白色部分，约占人眼总面积的30%，眼睛的中心为瞳孔部分，约占5%，虹膜位于巩膜和瞳孔之间，约占整个眼睛的65%，包含了最丰富的纹理信息，外观上看，虹膜由许多腺窝、褶皱、色素斑等构成，是人体中最独特的结构之一。因为瞳孔、虹膜和巩膜一般颜色不同，灰度值呈梯度变化，所以根据它们灰度不同，可以将它们明显分开。从几何形状可以看出，虹膜的内、外边界可以近似为圆形，这使它具有易检测性。临床观察发现：虹膜在人的一生当中几乎不发生变化，只有很少的虹膜纹理可能会由于年龄或者外伤导致纹理破坏。&lt;/font&gt;&lt;/div&gt;
&lt;div style=&#34;width:800px;&#34;&gt;&lt;font color=#000000 size = 5 &gt;&amp;emsp;&amp;emsp;作为表示个人身份的标识物，必须具备作为身份标识的重要特征。人脸、指纹等许多生物特征具有作为身份标识的特性，但是，虹膜在这些特性方面表现的更为突出，具有许多先天优势，是其他生物特征无法与之媲美的。&lt;/font&gt;
&lt;div style=&#34;width:800px;&#34;&gt;&lt;font color=#000000 size = 5 &gt;&lt;ul type=&#39;circle&#39;&gt;&lt;li&gt;普遍性————虹膜是每个人天生都具有的。&lt;/li&gt;&lt;li&gt;唯一性————虹膜的纤维组织细节复杂而丰富，每个人错综复杂的虹膜独一无二，只与虹膜的形成过程有关。&lt;/li&gt;&lt;li&gt;稳定性————虹膜从婴儿胚胎发育的第三个月起开始发育，到第八个月虹膜的主要纹理结构已经成形。&lt;/li&gt;&lt;li&gt;非入侵检测————从一定距离即可获得虹膜数字图像，无需用户接触设备。&lt;/li&gt;&lt;li&gt;可接受程度好————虹膜识别以其认证准确度高、速度快、安全性高，被用户所接受。&lt;/li&gt;&lt;li&gt;可检测性————利用图像处理技术检测出虹膜边界，易于拟合分割和和归一化&lt;/li&gt;&lt;li&gt;防伪性高————虹膜的半径小，在可见光下中国人的虹膜图像呈现深褐色，看不到纹理信息，需要虹膜图像专业采集设备和用户的配合，所以一般情况下很难被盗取&lt;/li&gt;&lt;li&gt;防欺骗性好————虹膜的唯一性决定了不同人眼的虹膜很难被冒充模仿。&lt;/li&gt;&lt;/ul&gt;
&lt;div style=&#34;width:800px;&#34;&gt;&lt;font color=#000000 size = 5 &gt;&amp;emsp;&amp;emsp;生物特征识别通过捕获生物样本，然后采用数学方法把样本转化成相同大小的模板，提取有效的可区别性特征，就可以客观地和其他一个完整的虹膜身份识别系统主要由四个部分组成：虹膜图像获取、虹膜图像预处理、虹膜特征提取、模式比对。
&lt;/font&gt;
&lt;div style=&#34;width:800px;&#34;&gt;&lt;font color=#000000 size = 5 &gt;&lt;ol&gt;&lt;li&gt;虹膜图像获取&lt;/li&gt;  
&amp;emsp;虹膜图像采集的目的是为了获取有效的虹膜图像，在传统的虹膜识别场景中，通常采用专业的成像装置在近红外光（波长700nm到900nm）照射和用户的配合下才能捕获清晰的高分辨率虹膜图像。近些年来，随着光学镜头、传感器和计算成像技术等的发展，虹膜识别的可用距离不断变大，相关装置也变得越来越轻巧实用，“远距离”、“行进中”、“移动端”和“可见光下”等少约束场景的虹膜识别对于用户使用时的约束越来越少，极大地提升了虹膜识别应用范围和用户友好性。
&lt;li&gt;虹膜图像预处理&lt;/li&gt;
虹膜图像除了必须的虹膜区域以外，也包含了诸如巩膜、睫毛、瞳孔等非虹膜区域，因此不能直接用于虹膜识别。其次，一些噪声茹照明变化、睫毛遮挡、镜面反射、瞳孔放缩等会明显增加虹膜的类内差异，降低虹膜的识别率。常规的虹膜预处理步骤包括：虹膜活体检测、虹膜图像质量评估、虹膜分割、虹膜归一化和虹膜图像增强。
&lt;li&gt;虹膜图像特征分析&lt;/li&gt;
虹膜图像特征分析主要包含两部分：特征提取和对比分类。虹膜特征提取是指从归一化的虹膜图像中提取紧凑有区分的虹膜特征，然后使用计算机可以存储和读取的格式进行编码。虹膜比对和分类(或者称为匹配)是指将提取的虹膜特征编码和事先在数据库注册过的虹膜特征编码通过某种相似性度量比如汉明距离、余弦距离进行对比，计算相似性分数，依次确定用户身份。
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Light Field Photography</title>
      <link>https://hycasia.github.io/project/light-field-photography/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://hycasia.github.io/project/light-field-photography/</guid>
      <description>&lt;h2 id=&#34;light-field&#34;&gt;Light field&lt;/h2&gt;
&lt;p&gt;The light field is a vector function that describes the amount of light flowing in every direction through every point in space. The space of all possible light rays is given by the five-dimensional plenoptic function, and the magnitude of each ray is given by the radiance. Michael Faraday was the first to propose (in an 1846 lecture entitled &amp;ldquo;Thoughts on Ray Vibrations&amp;rdquo;) that light should be interpreted as a field, much like the magnetic fields on which he had been working for several years. The phrase light field was coined by Andrey Gershun in a classic paper on the radiometric properties of light in three-dimensional space (1936).&lt;/p&gt;
&lt;h2 id=&#34;the-4d-light-field&#34;&gt;The 4D light field&lt;/h2&gt;
&lt;p&gt;In a plenoptic function, if the region of interest contains a concave object (think of a cupped hand), then light leaving one point on the object may travel only a short distance before being blocked by another point on the object. No practical device could measure the function in such a region.&lt;/p&gt;
&lt;p&gt;However, if we restrict ourselves to locations outside the convex hull (think shrink-wrap) of the object, i.e. in free space, then we can measure the plenoptic function by taking many photos using a digital camera. Moreover, in this case the function contains redundant information, because the radiance along a ray remains constant from point to point along its length, as shown at left. In fact, the redundant information is exactly one dimension, leaving us with a four-dimensional function (that is, a function of points in a particular four-dimensional manifold). Parry Moon dubbed this function the photic field (1981), while researchers in computer graphics call it the 4D light field (Levoy 1996) or Lumigraph (Gortler 1996). Formally, the 4D light field is defined as radiance along rays in empty space.&lt;/p&gt;
&lt;p&gt;The set of rays in a light field can be parameterized in a variety of ways, a few of which are shown below. Of these, the most common is the two-plane parameterization shown at right (below). While this parameterization cannot represent all rays, for example rays parallel to the two planes if the planes are parallel to each other, it has the advantage of relating closely to the analytic geometry of perspective imaging. Indeed, a simple way to think about a two-plane light field is as a collection of perspective images of the st plane (and any objects that may lie astride or beyond it), each taken from an observer position on the uv plane. A light field parameterized this way is sometimes called a light slab.&lt;/p&gt;
&lt;h2 id=&#34;ways-to-create-light-fields&#34;&gt;Ways to create light fields&lt;/h2&gt;
&lt;p&gt;Light fields are a fundamental representation for light. As such, there are as many ways of creating light fields as there are computer programs capable of creating images or instruments capable of capturing them.&lt;/p&gt;
&lt;p&gt;In computer graphics, light fields are typically produced either by rendering a 3D model or by photographing a real scene. In either case, to produce a light field views must be obtained for a large collection of viewpoints. Depending on the parameterization employed, this collection will typically span some portion of a line, circle, plane, sphere, or other shape, although unstructured collections of viewpoints are also possible (Buehler 2001).&lt;/p&gt;
&lt;p&gt;Devices for capturing light fields photographically may include a moving handheld camera or a robotically controlled camera (Levoy 2002), an arc of cameras (as in the bullet time effect used in The Matrix), a dense array of cameras (Kanade 1998; Yang 2002; Wilburn 2005), handheld cameras (Ng 2005; Georgiev 2006; Marwah 2013), microscopes (Levoy 2006), or other optical system (Bolles 1987).&lt;/p&gt;
&lt;p&gt;How many images should be in a light field? The largest known light field (of Michelangelo&amp;rsquo;s statue of Night) contains 24,000 1.3-megapixel images. At a deeper level, the answer depends on the application. For light field rendering (see the Application section below), if you want to walk completely around an opaque object, then of course you need to photograph its back side. Less obviously, if you want to walk close to the object, and the object lies astride the st plane, then you need images taken at finely spaced positions on the uv plane (in the two-plane parameterization shown above), which is now behind you, and these images need to have high spatial resolution.&lt;/p&gt;
&lt;p&gt;The number and arrangement of images in a light field, and the resolution of each image, are together called the &amp;ldquo;sampling&amp;rdquo; of the 4D light field. Analyses of light field sampling have been undertaken by many researchers; a good starting point is Chai (2000). Also of interest is Durand (2005) for the effects of occlusion, Ramamoorthi (2006) for the effects of lighting and reflection, and Ng (2005) and Zwicker (2006) for applications to plenoptic cameras and 3D displays, respectively.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Periocular Recognition</title>
      <link>https://hycasia.github.io/project/periocular-recognition/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://hycasia.github.io/project/periocular-recognition/</guid>
      <description>&lt;div style=&#34;width:800px;&#34;&gt;&lt;font color=#000000 size = 7 &gt;&lt;strong&gt;To be updated.....&lt;/strong&gt;&lt;/font&gt;</description>
    </item>
    
    <item>
      <title>Sclera Recognition</title>
      <link>https://hycasia.github.io/project/sclera-recognition/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://hycasia.github.io/project/sclera-recognition/</guid>
      <description>&lt;div style=&#34;width:800px;&#34;&gt;&lt;font color=#000000 size = 7 &gt;&lt;strong&gt;To be updated.....&lt;/strong&gt;&lt;/font&gt;</description>
    </item>
    
  </channel>
</rss>
